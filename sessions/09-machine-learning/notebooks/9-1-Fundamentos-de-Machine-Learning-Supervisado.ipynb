{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8753513e",
   "metadata": {},
   "source": [
    "# Fundamentos de Machine Learning Supervisado\n",
    "\n",
    "**Curso:** “Fundamentos de Programación y Analítica de Datos con Python”  \n",
    "**Duración estimada del bloque:** 2 horas\n",
    "\n",
    "## Objetivos específicos\n",
    "- Diferenciar formalmente entre aprendizaje supervisado, clasificación y regresión, identificando variables de entrada y variable objetivo.\n",
    "- Preparar datos básicos para clasificación (train/test split, estandarización opcional) y justificar decisiones.\n",
    "- Entrenar y evaluar modelos de clasificación binaria y multiclase con regresión logística y árboles de decisión.\n",
    "- Seleccionar y reportar métricas adecuadas (accuracy, precision, recall, F1, AUC-ROC) según el contexto del problema.\n",
    "\n",
    "## Prerrequisitos\n",
    "- Conocimientos fundamentales de Python (tipos, control de flujo, funciones).\n",
    "- Nociones de NumPy, Pandas y visualización básica con Matplotlib.\n",
    "- Instalación de librerías: `numpy`, `pandas`, `scikit-learn`, `matplotlib`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d740a49",
   "metadata": {},
   "source": [
    "## Tema 1 — Introducción al Aprendizaje Supervisado\n",
    "\n",
    "### Definición\n",
    "El aprendizaje supervisado es un paradigma de *Machine Learning* en el que se dispone de **observaciones etiquetadas** \\((\\mathbf{x}_i, y_i)\\), donde \\(\\mathbf{x}_i\\) es un vector de características y \\(y_i\\) es la etiqueta (clase para clasificación; valor continuo para regresión). El objetivo es **aprender una función** \\(f: \\mathbb{R}^p \\to \\mathcal{Y}\\) que generalice y permita predecir \\(y\\) para **nuevas** instancias \\(\\mathbf{x}\\).\n",
    "\n",
    "### Importancia en programación y analítica de datos\n",
    "- Permite construir **sistemas predictivos** para soporte de decisiones (por ejemplo, detección de fraude o clasificación de spam).\n",
    "- Exige una **pipeline reproducible**: carga de datos, preprocesamiento, entrenamiento, evaluación y despliegue.\n",
    "- Introduce buenas prácticas de **validación** (train/test split, cross-validation) y **métricas** pertinentes al negocio.\n",
    "\n",
    "### Buenas prácticas profesionales y errores comunes\n",
    "- **Buenas prácticas:**\n",
    "  - Fijar `random_state` para resultados reproducibles.\n",
    "  - Separar conjunto de **entrenamiento** y **prueba** antes de explorar desempeño.\n",
    "  - Estandarizar características cuando el modelo sea **sensible a escala** (e.g., modelos lineales).\n",
    "- **Errores comunes:**\n",
    "  - Fuga de datos (*data leakage*): usar información del conjunto de prueba durante el preprocesamiento.\n",
    "  - Confiar solo en `accuracy` en conjuntos desbalanceados; preferir F1, AUC-ROC o precisión/recobrado por clase.\n",
    "\n",
    "### Ejemplo en Python\n",
    "A continuación, se ilustra el flujo mínimo: carga de un dataset de `scikit-learn`, división train/test y verificación de tamaños."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194d918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flujo mínimo de aprendizaje supervisado: carga de datos y train/test split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# 1) Cargar dataset (clasificación binaria)\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# 2) División estratificada para preservar proporciones de clases\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Dimensiones X:\", X.shape, \"| y:\", y.shape)\n",
    "print(\"Train:\", X_train.shape, y_train.shape, \"| Test:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# Distribución de clases\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(\"Distribución total de clases:\", dict(zip(unique, counts)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c19608",
   "metadata": {},
   "source": [
    "## Tema 2 — Regresión Logística (Clasificación Binaria)\n",
    "\n",
    "### Definición\n",
    "La **regresión logística** modela la **probabilidad** de pertenecer a una clase (por ejemplo, \\(y=1\\)) mediante la función sigmoide:  \n",
    "\\[ \\hat{p}(y=1\\mid \\mathbf{x}) = \\sigma(\\mathbf{w}^\\top \\mathbf{x} + b), \\quad \\sigma(z) = \\frac{1}{1 + e^{-z}}. \\]\n",
    "Se entrena minimizando la **entropía cruzada** (log-loss). La decisión de clase se obtiene con un **umbral** (por defecto 0.5).\n",
    "\n",
    "### Importancia en programación y analítica de datos\n",
    "- Modelo **rápido** y base para líneas de producción con alta interpretabilidad (coeficientes).\n",
    "- Adecuado como **baseline** en numerosos problemas antes de modelos más complejos.\n",
    "- Requiere atención a **escala** de variables y **regularización** para evitar sobreajuste.\n",
    "\n",
    "### Buenas prácticas profesionales y errores comunes\n",
    "- Escalar características (e.g., `StandardScaler`) para mejorar la convergencia.\n",
    "- Verificar **multicolinealidad** y realizar selección/ingeniería de características cuando sea necesario.\n",
    "- Evitar interpretar coeficientes sin considerar escala y regularización.\n",
    "\n",
    "### Ejemplo en Python\n",
    "Entrenamiento, predicción y métricas básicas en un dataset binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb9d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pipeline: estandarización + regresión logística\n",
    "logreg = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(max_iter=1000, random_state=42)\n",
    ")\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# AUC-ROC\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "print(\"AUC-ROC:\", round(auc, 4))\n",
    "\n",
    "# Curva ROC\n",
    "RocCurveDisplay.from_estimator(logreg, X_test, y_test)\n",
    "plt.title(\"Curva ROC - Regresión Logística\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41246f2a",
   "metadata": {},
   "source": [
    "## Tema 3 — Árboles de Decisión\n",
    "\n",
    "### Definición\n",
    "Un **árbol de decisión** realiza particiones recursivas del espacio de características usando reglas del tipo *si-entonces*. En clasificación, utiliza medidas de impureza como **Gini** o **Entropía** para seleccionar divisiones.\n",
    "\n",
    "### Importancia en programación y analítica de datos\n",
    "- Modelo **interpretable** (reglas) y capaz de capturar **relaciones no lineales** e **interacciones**.\n",
    "- Suele requerir **menos preprocesamiento** que modelos lineales.\n",
    "- Constituye la base de métodos **ensamblados** (Random Forest, Gradient Boosting).\n",
    "\n",
    "### Buenas prácticas profesionales y errores comunes\n",
    "- Controlar la **profundidad** (`max_depth`) y el **número mínimo de muestras por división** para evitar sobreajuste.\n",
    "- Evaluar desempeño con **validación cruzada** si es posible.\n",
    "- No utilizar árboles sin restricción en datasets pequeños: alta varianza.\n",
    "\n",
    "### Ejemplo en Python\n",
    "Entrenamiento, visualización sintética del árbol y evaluación de métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1077191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",\n",
    "    max_depth=4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "\n",
    "# Métricas básicas\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(\"Accuracy (Árbol):\", accuracy_score(y_test, y_pred_tree))\n",
    "print(\"\\nClassification Report (Árbol):\\n\", classification_report(y_test, y_pred_tree))\n",
    "\n",
    "# Matriz de confusión\n",
    "ConfusionMatrixDisplay.from_estimator(tree_clf, X_test, y_test)\n",
    "plt.title(\"Matriz de Confusión - Árbol de Decisión\")\n",
    "plt.show()\n",
    "\n",
    "# Visualización del árbol (puede ser grande; se fija max_depth para claridad)\n",
    "plt.figure(figsize=(14, 6))\n",
    "plot_tree(\n",
    "    tree_clf,\n",
    "    filled=True,\n",
    "    feature_names=load_breast_cancer().feature_names,\n",
    "    class_names=[\"No\", \"Sí\"]\n",
    ")\n",
    "plt.title(\"Árbol de Decisión (profundidad limitada)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ec98df",
   "metadata": {},
   "source": [
    "## Tema 4 — Evaluación de Modelos Supervisados\n",
    "\n",
    "### Definición\n",
    "La **evaluación** valora la calidad predictiva de un modelo en datos **no vistos**. En clasificación se emplean métricas como:\n",
    "- **Accuracy**: proporción de aciertos totales.\n",
    "- **Precision/Recall**: precisión y exhaustividad para clases positivas.\n",
    "- **F1-score**: media armónica de precisión y recall.\n",
    "- **AUC-ROC**: área bajo la curva ROC, robusta a umbrales.\n",
    "\n",
    "### Importancia en programación y analítica de datos\n",
    "- Permite **comparar modelos** y seleccionar configuraciones de hiperparámetros.\n",
    "- Fomenta decisiones informadas según el **costo del error** (falsos positivos vs falsos negativos).\n",
    "- Esencial para comunicar resultados a **stakeholders**.\n",
    "\n",
    "### Buenas prácticas profesionales y errores comunes\n",
    "- Reportar **múltiples métricas** y **curvas** (ROC, PR) cuando hay desbalance.\n",
    "- Usar **estratificación** en `train_test_split` y **validación cruzada** para estimar generalización.\n",
    "- Evitar optimizar exclusivamente una métrica sin comprender el contexto del problema.\n",
    "\n",
    "### Ejemplo en Python\n",
    "Comparación rápida entre modelos (regresión logística vs árbol) usando F1 macro y AUC cuando aplique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f05648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Aseguramos dos modelos comparables\n",
    "logreg_model = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, random_state=42))\n",
    "tree_model = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_log = logreg_model.predict(X_test)\n",
    "y_proba_log = logreg_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "\n",
    "# Métricas\n",
    "f1_log = f1_score(y_test, y_pred_log, average=\"macro\")\n",
    "f1_tree = f1_score(y_test, y_pred_tree, average=\"macro\")\n",
    "auc_log = roc_auc_score(y_test, y_proba_log)\n",
    "\n",
    "print(f\"F1 (LogReg): {f1_log:.4f}\")\n",
    "print(f\"F1 (Árbol):  {f1_tree:.4f}\")\n",
    "print(f\"AUC (LogReg): {auc_log:.4f}  # AUC no aplica directamente a predicciones discretas del árbol sin calibrated proba\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75226b0f",
   "metadata": {},
   "source": [
    "# Ejercicios Integradores\n",
    "\n",
    "A continuación, se proponen ejercicios que articulan los conceptos del bloque. Cada ejercicio incluye **contexto técnico**, **datos/entradas**, **requerimientos**, **criterios de aceptación** y **pistas**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b98345",
   "metadata": {},
   "source": [
    "## Ejercicio 1 — Baseline reproducible con Regresión Logística\n",
    "\n",
    "**Contexto técnico:** Eres analista de datos en una clínica y necesitas un **baseline** reproducible para clasificar pacientes en dos grupos según medidas diagnósticas. El equipo clínico solicita un primer **informe de desempeño**.\n",
    "\n",
    "**Datos/entradas:** Usa `load_breast_cancer` de `sklearn`. Divide los datos en `train/test` con estratificación y `random_state=42`.\n",
    "\n",
    "**Requerimientos:**\n",
    "- Construir un *pipeline* `StandardScaler` + `LogisticRegression(max_iter=1000)`.\n",
    "- Reportar `accuracy`, `precision`, `recall`, `F1` y `AUC-ROC` en test.\n",
    "- Graficar la curva ROC.\n",
    "\n",
    "**Criterios de aceptación:**\n",
    "- Código reproducible y bien comentado.\n",
    "- Reporte impreso de métricas y visualización de la curva ROC.\n",
    "- Explicación breve de cuándo **accuracy** puede ser insuficiente.\n",
    "\n",
    "**Pistas:**\n",
    "- Usa `make_pipeline`, `classification_report`, `RocCurveDisplay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1153ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solución propuesta (puedes ocultar esta celda al evaluar)\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, random_state=42))\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "RocCurveDisplay.from_estimator(pipe, X_test, y_test)\n",
    "plt.title(\"Curva ROC - Baseline Regresión Logística\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734c8954",
   "metadata": {},
   "source": [
    "## Ejercicio 2 — Árbol de Decisión con control de complejidad\n",
    "\n",
    "**Contexto técnico:** En una auditoría de calidad, necesitas un modelo interpretable con **reglas** claras para justificar decisiones ante un auditor externo.\n",
    "\n",
    "**Datos/entradas:** Usa `load_breast_cancer`. División 75/25 con estratificación, `random_state=7`.\n",
    "\n",
    "**Requerimientos:**\n",
    "- Entrenar `DecisionTreeClassifier` con `max_depth` en {3, 5, None} y compararlos.\n",
    "- Reportar `accuracy` y `F1 macro` en test para cada profundidad.\n",
    "- Graficar la **matriz de confusión** del mejor modelo.\n",
    "\n",
    "**Criterios de aceptación:**\n",
    "- Evidencia de **sobreajuste** cuando `max_depth=None` frente a profundidades limitadas.\n",
    "- Selección justificada del mejor modelo con base en métricas.\n",
    "\n",
    "**Pistas:**\n",
    "- Usa `ConfusionMatrixDisplay` y asegúrate de fijar `random_state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcff5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solución propuesta\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=7\n",
    ")\n",
    "\n",
    "best_model, best_f1 = None, -1\n",
    "for depth in [3, 5, None]:\n",
    "    clf = DecisionTreeClassifier(max_depth=depth, random_state=7)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Depth={depth} -> F1={f1:.4f} | Acc={acc:.4f}\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_model = f1, clf\n",
    "\n",
    "print(\"\\nMejor profundidad según F1:\", best_model.get_params().get(\"max_depth\"))\n",
    "ConfusionMatrixDisplay.from_estimator(best_model, X_test, y_test)\n",
    "plt.title(\"Matriz de confusión - Mejor Árbol\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b10f6",
   "metadata": {},
   "source": [
    "## Ejercicio 3 — Elección de métrica bajo desbalance\n",
    "\n",
    "**Contexto técnico:** En un sistema de monitoreo, los **falsos negativos** son costosos. Se te pide priorizar **recall** sobre otras métricas.\n",
    "\n",
    "**Datos/entradas:** Crea un dataset sintético desbalanceado con `make_classification` (clase positiva 10–15%).\n",
    "\n",
    "**Requerimientos:**\n",
    "- Entrenar Regresión Logística y Árbol (con `class_weight='balanced'` en ambos cuando aplique).\n",
    "- Comparar `recall`, `precision` y `F1` de ambos modelos en test.\n",
    "- Ajustar el **umbral** de decisión de la logística para maximizar `recall` manteniendo `precision` aceptable.\n",
    "\n",
    "**Criterios de aceptación:**\n",
    "- Mostrar cómo `class_weight` y el **umbral** afectan las métricas.\n",
    "- Reporte claro de la **trade-off** precisión–recobrado.\n",
    "\n",
    "**Pistas:**\n",
    "- Usa `predict_proba` en la logística y barre umbrales con `np.linspace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a7ec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solución propuesta\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Dataset desbalanceado\n",
    "X, y = make_classification(\n",
    "    n_samples=3000, n_features=12, n_informative=6, n_redundant=2,\n",
    "    weights=[0.88, 0.12], flip_y=0.01, random_state=42\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Modelos con class_weight='balanced'\n",
    "logreg = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42))\n",
    "tree = DecisionTreeClassifier(max_depth=6, class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones con umbral por defecto\n",
    "y_pred_log = logreg.predict(X_test)\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "\n",
    "def report(name, y_true, y_pred):\n",
    "    p = precision_score(y_true, y_pred, zero_division=0)\n",
    "    r = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"{name:>10s} -> Precision={p:.3f} | Recall={r:.3f} | F1={f1:.3f}\")\n",
    "\n",
    "report(\"LogReg@0.5\", y_test, y_pred_log)\n",
    "report(\"Tree\", y_test, y_pred_tree)\n",
    "\n",
    "# Barrido de umbral para maximizar recall aceptable\n",
    "y_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "thresholds = np.linspace(0.05, 0.8, 16)\n",
    "best = None\n",
    "for t in thresholds:\n",
    "    y_hat = (y_proba >= t).astype(int)\n",
    "    p = precision_score(y_test, y_hat, zero_division=0)\n",
    "    r = recall_score(y_test, y_hat)\n",
    "    f1 = f1_score(y_test, y_hat)\n",
    "    if best is None or (r > best[1] and p >= 0.30):  # ejemplo de restricción mínima de precisión\n",
    "        best = (t, r, p, f1)\n",
    "\n",
    "print(f\"\\nMejor umbral con precisión >= 0.30 -> t={best[0]:.2f}, recall={best[1]:.3f}, precision={best[2]:.3f}, F1={best[3]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c70d63e",
   "metadata": {},
   "source": [
    "## Ejercicio 4 — Validación cruzada y selección simple de modelo\n",
    "\n",
    "**Contexto técnico:** Como *ML engineer* debes presentar una **comparación justa** entre dos modelos base usando validación cruzada estratificada.\n",
    "\n",
    "**Datos/Eentradas:** Usa `load_breast_cancer`. Emplea `StratifiedKFold(n_splits=5, shuffle=True, random_state=42)`.\n",
    "\n",
    "**Requerimientos:**\n",
    "- Comparar `LogisticRegression` (con `StandardScaler`) vs `DecisionTreeClassifier` (profundidad 3–6).\n",
    "- Reportar media y desviación estándar de `F1 macro` por validación cruzada.\n",
    "- Seleccionar el mejor y reentrenar en el conjunto completo de entrenamiento, evaluando en test.\n",
    "\n",
    "**Criterios de aceptación:**\n",
    "- Uso correcto de `Pipeline`/`make_pipeline` y `cross_val_score`.\n",
    "- Justificación de la elección final basada en **estadística descriptiva** de CV.\n",
    "\n",
    "**Pistas:**\n",
    "- Usa `cross_val_score` con `scoring='f1_macro'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78dff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solución propuesta\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "logreg = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, random_state=42))\n",
    "tree_candidates = [DecisionTreeClassifier(max_depth=d, random_state=42) for d in range(3, 7)]\n",
    "\n",
    "def cv_summary(model):\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=\"f1_macro\")\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "mean_log, std_log = cv_summary(logreg)\n",
    "print(f\"LogReg  -> F1_macro CV: {mean_log:.4f} ± {std_log:.4f}\")\n",
    "\n",
    "best_tree, best_mean, best_std = None, -1, None\n",
    "for m in tree_candidates:\n",
    "    mean, std = cv_summary(m)\n",
    "    print(f\"Tree(d={m.max_depth}) -> F1_macro CV: {mean:.4f} ± {std:.4f}\")\n",
    "    if mean > best_mean:\n",
    "        best_tree, best_mean, best_std = m, mean, std\n",
    "\n",
    "# Selección\n",
    "print(f\"\\nMejor árbol en CV: depth={best_tree.max_depth} con {best_mean:.4f} ± {best_std:.4f}\")\n",
    "\n",
    "# Comparación final reentrenando y evaluando en test\n",
    "logreg.fit(X_train, y_train)\n",
    "best_tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred_log = logreg.predict(X_test)\n",
    "y_pred_tree = best_tree.predict(X_test)\n",
    "\n",
    "print(f\"F1_macro Test (LogReg): {f1_score(y_test, y_pred_log, average='macro'):.4f}\")\n",
    "print(f\"F1_macro Test (Tree):   {f1_score(y_test, y_pred_tree, average='macro'):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "authors": [
   "Jhon Erik Navarrete Gómez",
   "Curso: Fundamentos de Programación y Analítica de Datos con Python"
  ],
  "created": "2025-09-16T18:49:10Z",
  "description": "Bloque 9.1 - Fundamentos de Machine Learning Supervisado: conceptos, modelos lineales y árboles, y evaluación de modelos.",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
