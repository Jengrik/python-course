{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2891e006",
   "metadata": {},
   "source": [
    "# Manipulación y Transformación de Datos con Pandas\n",
    "**Curso:** Fundamentos de Programación y Analítica de Datos con Python  \n",
    "\n",
    "**Duración estimada del bloque:** 2 horas (Sección aplicada dentro de la Sesión 5)  \n",
    "\n",
    "**Objetivos específicos**\n",
    "- Importar y exportar datasets en formatos comunes (CSV y Excel) utilizando Pandas.\n",
    "- Seleccionar y filtrar subconjuntos de datos con `loc`, `iloc` y condiciones booleanas compuestas.\n",
    "- Aplicar operaciones de agregación y transformación con `groupby`, `agg` y `apply` para obtener métricas y nuevas variables.\n",
    "- Adoptar buenas prácticas de limpieza, tipificación y documentación del proceso de manipulación de datos.\n",
    "\n",
    "**Prerrequisitos**\n",
    "- Conocimientos básicos de Python (tipos, listas, diccionarios, funciones).\n",
    "- Nociones elementales de NumPy (arrays y operaciones vectorizadas).\n",
    "- Conocimientos mínimos de estructura tabular (filas/columnas) y estadística descriptiva básica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439f0636",
   "metadata": {},
   "source": [
    "## Tema 1. Carga y Exportación de Datos (CSV / Excel)\n",
    "\n",
    "### Definición\n",
    "Operaciones de **entrada/salida (I/O)** para leer datos desde archivos externos (CSV, Excel) hacia un `DataFrame` de Pandas y para **persistir** resultados de procesamiento con `to_csv` / `to_excel`.\n",
    "\n",
    "### Importancia en programación y analítica de datos\n",
    "- Los datos en entornos reales provienen de fuentes heterogéneas; la **ingesta fiable** es el primer paso del pipeline.\n",
    "- La capacidad de **persistir** resultados garantiza reproducibilidad, intercambio e integración con otras herramientas (BI, hojas de cálculo, SQL).\n",
    "- Parámetros de lectura correctos (separador, codificación, tipos) evitan errores de calidad de datos desde el inicio.\n",
    "\n",
    "### Buenas prácticas profesionales y errores comunes\n",
    "- **Buenas prácticas:** especificar parámetros relevantes (`sep`, `encoding`, `dtype`, `usecols`, `parse_dates`), validar con `.head()`, `.info()`, y documentar supuestos.\n",
    "- **Errores comunes:** depender del autoinferido de tipos sin validación; no controlar separadores o codificaciones; exportar con índices no deseados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d237d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Ejemplo en Python: lectura y escritura segura con Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf8251d",
   "metadata": {},
   "source": [
    "## Tema 2. Selección y Filtrado: `loc`, `iloc` y Condiciones\n",
    "\n",
    "### Definición\n",
    "**Selección** de filas/columnas por **etiqueta** (`loc`) o por **posición** (`iloc`) y **filtrado** mediante condiciones booleanas simples o compuestas.\n",
    "\n",
    "### Importancia en programación y analítica de datos\n",
    "- Permite construir subconjuntos para **análisis focalizado**, limpieza dirigida y verificación de hipótesis.\n",
    "- Es la base para preparar datasets de modelado y para aplicar transformaciones específicas por segmentos.\n",
    "\n",
    "### Buenas prácticas profesionales y errores comunes\n",
    "- **Buenas prácticas:** preferir `loc` cuando se conocen etiquetas; usar máscaras booleans legibles; encadenar condiciones con `&`, `|` y paréntesis.\n",
    "- **Errores comunes:** olvidar paréntesis al combinar condiciones; confundir `loc` (incluye extremo superior en slices) con `iloc` (excluye extremo superior)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c006bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Ejemplo en Python: loc, iloc y filtros compuestos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d662d700",
   "metadata": {},
   "source": [
    "## Tema 3. Operaciones de Agregación y Transformación: `groupby`, `agg`, `apply`\n",
    "\n",
    "### Definición\n",
    "- `groupby`: particiona el `DataFrame` en grupos según una o más columnas.\n",
    "- `agg`: aplica funciones de **agregación** (p. ej., `sum`, `mean`, `count`) por grupo.\n",
    "- `apply`: aplica una función arbitraria a cada grupo/serie para **transformaciones personalizadas**.\n",
    "\n",
    "### Importancia en programación y analítica de datos\n",
    "- Facilita el cálculo de **métricas resumidas** por categoría, periodo o segmento.\n",
    "- Permite construir **features** y reglas de negocio (KPIs) a partir de datos brutos.\n",
    "\n",
    "### Buenas prácticas profesionales y errores comunes\n",
    "- **Buenas prácticas:** nombrar columnas agregadas con alias claros; validar cardinalidades; evitar `apply` cuando una operación vectorizada es suficiente.\n",
    "- **Errores comunes:** no resetear el índice tras agregaciones; usar `apply` de forma innecesaria (penaliza rendimiento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f43c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Ejemplo en Python: groupby, agg y apply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e49a95",
   "metadata": {},
   "source": [
    "# Ejercicios Integradores\n",
    "\n",
    "A continuación se proponen ejercicios que integran carga, selección/filtrado y agregación/transformación. Se presentan **pistas** y, posteriormente, una **solución propuesta**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977911b2",
   "metadata": {},
   "source": [
    "## Ejercicio 1. Reporte de ventas por categoría y ticket promedio\n",
    "**Contexto técnico:** Eres analista de Business Intelligence en una tienda en línea. Debes generar un **reporte semanal** para dirección con métricas por categoría que orienten decisiones de pricing y stock.\n",
    "\n",
    "**Datos / entradas:** Utiliza un `DataFrame` con columnas `categoria`, `precio`, `unidades` y `fecha`. Puedes partir de un CSV simulado en memoria (similar a los ejemplos).\n",
    "\n",
    "**Requerimientos:**\n",
    "1. Calcular **ventas totales** por categoría (`precio * unidades`).\n",
    "2. Calcular el **ticket promedio** por categoría (promedio de `precio` ponderado por `unidades` o simple, justifica tu elección).\n",
    "3. Ordenar el resultado por ventas totales descendente.\n",
    "\n",
    "**Criterios de aceptación:**\n",
    "- El resultado debe ser un `DataFrame` con columnas: `categoria`, `ventas_totales`, `ticket_promedio`.\n",
    "- Debe estar ordenado por `ventas_totales` de mayor a menor.\n",
    "- Debes mostrar las 5 primeras filas con `.head()`.\n",
    "\n",
    "**Pistas:**\n",
    "- Crea una columna auxiliar `venta = precio * unidades`.\n",
    "- Usa `groupby('categoria').agg(...)` con alias de columnas.\n",
    "- Para ticket promedio ponderado, usa una razón de sumatorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83247941",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Solución Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e457b8ec",
   "metadata": {},
   "source": [
    "## Ejercicio 2. Segmentación temporal y filtrado avanzado\n",
    "**Contexto técnico:** Como analista de datos, debes preparar un **subset** de registros para un experimento A/B que solo considera transacciones realizadas **a partir** de una fecha y con **precio** dentro de un rango específico.\n",
    "\n",
    "**Datos / entradas:** Un `DataFrame` con `fecha` (tipo fecha), `precio` y `categoria`.\n",
    "\n",
    "**Requerimientos:**\n",
    "1. Filtrar registros con `fecha >= 2024-01-04`.\n",
    "2. Mantener solo filas con `precio` en el rango `[20, 200]`.\n",
    "3. Seleccionar únicamente las columnas `fecha`, `categoria` y `precio`.\n",
    "4. Mostrar las primeras 3 filas resultantes.\n",
    "\n",
    "**Criterios de aceptación:**\n",
    "- El `DataFrame` filtrado solo contiene precios dentro del rango y fechas a partir del umbral.\n",
    "- Columnas en el orden solicitado.\n",
    "\n",
    "**Pistas:**\n",
    "- Recuerda usar paréntesis al combinar condiciones con `&`.\n",
    "- Usa `loc` para seleccionar columnas por etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14d84d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Solución Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d9c450",
   "metadata": {},
   "source": [
    "## Ejercicio 3. Enriquecimiento con transformaciones por grupo\n",
    "**Contexto técnico:** Como científico/a de datos, necesitas **normalizar** la columna `unidades` dentro de cada `categoria` para comparar el desempeño relativo entre productos, independientemente de su escala.\n",
    "\n",
    "**Datos / entradas:** `DataFrame` con `categoria` y `unidades` (enteros positivos).\n",
    "\n",
    "**Requerimientos:**\n",
    "1. Calcular el **z-score** por categoría sobre `unidades` y añadirlo como columna `z_unidades`.\n",
    "2. Comprobar que la media por categoría de `z_unidades` está cercana a 0.\n",
    "3. Mostrar una tabla con `categoria`, `unidades`, `z_unidades` (primeras 5 filas).\n",
    "\n",
    "**Criterios de aceptación:**\n",
    "- Nueva columna `z_unidades` creada correctamente.\n",
    "- Media por categoría de `z_unidades` ≈ 0 (diferencias menores por redondeo).\n",
    "\n",
    "**Pistas:**\n",
    "- Usa `groupby('categoria')['unidades'].transform(...)` con una función que aplique z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c38c75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Solución Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dc9cbd",
   "metadata": {},
   "source": [
    "## Ejercicio 4 (opcional). Exportación del resultado y validaciones mínimas\n",
    "**Contexto técnico:** Debes entregar a un equipo externo un **extracto** con métricas por categoría. El equipo requiere un archivo **Excel** con nombre y ubicación definidos.\n",
    "\n",
    "**Datos / entradas:** Resultado del **Ejercicio 1** u otro `DataFrame` agregado.\n",
    "\n",
    "**Requerimientos:**\n",
    "1. Validar que no existan valores nulos en las columnas clave.\n",
    "2. Exportar a Excel sin índice.\n",
    "3. Confirmar ruta de salida y tamaño del archivo.\n",
    "\n",
    "**Criterios de aceptación:**\n",
    "- Archivo `.xlsx` generado en la ruta configurada, sin índice.\n",
    "- Columnas clave sin nulos.\n",
    "\n",
    "**Pistas:**\n",
    "- Usa `notna().all()` para columnas clave.\n",
    "- Usa `to_excel(ruta, index=False)` y revisa con el sistema de archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfebfc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Solución Ejercicio 4"
   ]
  }
 ],
 "metadata": {
  "authors": [
   "Equipo docente - Fundamentos de Programación y Analítica de Datos con Python"
  ],
  "created": "2025-09-16T18:00:38.086380+00:00",
  "description": "Sección: Manipulación y Transformación de Datos con Pandas. Uso de Pandas para carga, selección/filtrado y operaciones de agregación/transformación sobre datos tabulares.",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
