{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2891e006",
   "metadata": {},
   "source": [
    "# Manipulación y Transformación de Datos con Pandas\n",
    "**Curso:** Fundamentos de Programación y Analítica de Datos con Python  \n",
    "\n",
    "**Duración estimada del bloque:** 2 horas (Sección aplicada dentro de la Sesión 5)  \n",
    "\n",
    "**Objetivos específicos**\n",
    "- Importar y exportar datasets en formatos comunes (CSV y Excel) utilizando Pandas.\n",
    "- Seleccionar y filtrar subconjuntos de datos con `loc`, `iloc` y condiciones booleanas compuestas.\n",
    "- Aplicar operaciones de agregación y transformación con `groupby`, `agg` y `apply` para obtener métricas y nuevas variables.\n",
    "- Adoptar buenas prácticas de limpieza, tipificación y documentación del proceso de manipulación de datos.\n",
    "\n",
    "**Prerrequisitos**\n",
    "- Conocimientos básicos de Python (tipos, listas, diccionarios, funciones).\n",
    "- Nociones elementales de NumPy (arrays y operaciones vectorizadas).\n",
    "- Conocimientos mínimos de estructura tabular (filas/columnas) y estadística descriptiva básica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439f0636",
   "metadata": {},
   "source": [
    "## Tema 1. Carga y Exportación de Datos (CSV / Excel)\n",
    "\n",
    "### Definición\n",
    "Operaciones de **entrada/salida (I/O)** para leer datos desde archivos externos (CSV, Excel) hacia un `DataFrame` de Pandas y para **persistir** resultados de procesamiento con `to_csv` / `to_excel`.\n",
    "\n",
    "### Importancia en programación y analítica de datos\n",
    "- Los datos en entornos reales provienen de fuentes heterogéneas; la **ingesta fiable** es el primer paso del pipeline.\n",
    "- La capacidad de **persistir** resultados garantiza reproducibilidad, intercambio e integración con otras herramientas (BI, hojas de cálculo, SQL).\n",
    "- Parámetros de lectura correctos (separador, codificación, tipos) evitan errores de calidad de datos desde el inicio.\n",
    "\n",
    "### Buenas prácticas profesionales y errores comunes\n",
    "- **Buenas prácticas:** especificar parámetros relevantes (`sep`, `encoding`, `dtype`, `usecols`, `parse_dates`), validar con `.head()`, `.info()`, y documentar supuestos.\n",
    "- **Errores comunes:** depender del autoinferido de tipos sin validación; no controlar separadores o codificaciones; exportar con índices no deseados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d237d720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del Dataframe:  (5, 6)\n",
      "   id         producto    categoria  precio      fecha  unidades\n",
      "0   1      Auriculares        Audio    35.5 2024-01-02         3\n",
      "1   2          Teclado  Periféricos    29.9 2024-01-03         2\n",
      "2   3          Monitor     Displays   199.0 2024-01-03         1\n",
      "3   4            Mouse  Periféricos    15.0 2024-01-04         5\n",
      "4   5  Barra de sonido        Audio   120.0 2024-01-05         1\n",
      "Tipo de datos inferidos:\n",
      " id                    int64\n",
      "producto             object\n",
      "categoria            object\n",
      "precio              float64\n",
      "fecha        datetime64[ns]\n",
      "unidades              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Ejemplo en Python: lectura y escritura segura con Pandas\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "\n",
    "#* Simulación de un CSV contenido en memoria\n",
    "csv_text = \"\"\"id,producto,categoria,precio,fecha,unidades\n",
    "1,Auriculares,Audio,35.5,2024-01-02,3\n",
    "2,Teclado,Periféricos,29.9,2024-01-03,2\n",
    "3,Monitor,Displays,199.0,2024-01-03,1\n",
    "4,Mouse,Periféricos,15.0,2024-01-04,5\n",
    "5,Barra de sonido,Audio,120.0,2024-01-05,1\n",
    "\"\"\"\n",
    "\n",
    "# Leer CSV desde memoria ( equivalente a leer desde un archivo: pd.read_csv('archivo.csv') )\n",
    "df = pd.read_csv(StringIO(csv_text), sep=',', encoding='utf-8', parse_dates=['fecha'])\n",
    "\n",
    "# Inspección Rápida\n",
    "print(\"Dimensiones del Dataframe: \", df.shape)\n",
    "print(df.head())\n",
    "print(\"Tipo de datos inferidos:\\n\", df.dtypes)\n",
    "\n",
    "out_dir = Path('./data')\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "csv_path = out_dir / 'productos.csv'\n",
    "xlsx_path = out_dir / 'productos.xlsx'\n",
    "\n",
    "# Exportar en archivos limpios\n",
    "df.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "df.to_excel(xlsx_path, index=False, engine='openpyxl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf8251d",
   "metadata": {},
   "source": [
    "## Tema 2. Selección y Filtrado: `loc`, `iloc` y Condiciones\n",
    "\n",
    "### Definición\n",
    "**Selección** de filas/columnas por **etiqueta** (`loc`) o por **posición** (`iloc`) y **filtrado** mediante condiciones booleanas simples o compuestas.\n",
    "\n",
    "### Importancia en programación y analítica de datos\n",
    "- Permite construir subconjuntos para **análisis focalizado**, limpieza dirigida y verificación de hipótesis.\n",
    "- Es la base para preparar datasets de modelado y para aplicar transformaciones específicas por segmentos.\n",
    "\n",
    "### Buenas prácticas profesionales y errores comunes\n",
    "- **Buenas prácticas:** preferir `loc` cuando se conocen etiquetas; usar máscaras booleans legibles; encadenar condiciones con `&`, `|` y paréntesis.\n",
    "- **Errores comunes:** olvidar paréntesis al combinar condiciones; confundir `loc` (incluye extremo superior en slices) con `iloc` (excluye extremo superior)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c006bdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset usando loc:\n",
      "           producto    categoria  precio\n",
      "0      Auriculares        Audio    35.5\n",
      "1          Teclado  Periféricos    29.9\n",
      "2          Monitor     Displays   199.0\n",
      "3            Mouse  Periféricos    15.0\n",
      "4  Barra de sonido        Audio   120.0\n",
      "Productos filtrados:\n",
      "    id producto    categoria  precio      fecha  unidades\n",
      "3   4    Mouse  Periféricos    15.0 2024-01-04         5\n",
      "Productos filtrados por fecha:\n",
      "    id         producto    categoria  precio      fecha  unidades\n",
      "3   4            Mouse  Periféricos    15.0 2024-01-04         5\n",
      "4   5  Barra de sonido        Audio   120.0 2024-01-05         1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Ejemplo en Python: loc, iloc y filtros compuestos\n",
    "\n",
    "df = pd.read_csv(\"./data/productos.csv\", parse_dates=['fecha'])\n",
    "\n",
    "# Selección por etiquetas de columnas con loc\n",
    "subset_loc = df.loc[:, ['producto', 'categoria', 'precio']]\n",
    "print(\"Subset usando loc:\\n\", subset_loc.head())\n",
    "\n",
    "# Filtrado adicional\n",
    "mask = (df[\"categoria\"] == \"Periféricos\") & (df[\"precio\"] < 20)\n",
    "filtrados = df[mask]\n",
    "print(\"Productos filtrados:\\n\", filtrados)\n",
    "\n",
    "filtrado_fecha = df[df[\"fecha\"] >= \"2024-01-04\"]\n",
    "print(\"Productos filtrados por fecha:\\n\", filtrado_fecha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d662d700",
   "metadata": {},
   "source": [
    "## Tema 3. Operaciones de Agregación y Transformación: `groupby`, `agg`, `apply`\n",
    "\n",
    "### Definición\n",
    "- `groupby`: particiona el `DataFrame` en grupos según una o más columnas.\n",
    "- `agg`: aplica funciones de **agregación** (p. ej., `sum`, `mean`, `count`) por grupo.\n",
    "- `apply`: aplica una función arbitraria a cada grupo/serie para **transformaciones personalizadas**.\n",
    "\n",
    "### Importancia en programación y analítica de datos\n",
    "- Facilita el cálculo de **métricas resumidas** por categoría, periodo o segmento.\n",
    "- Permite construir **features** y reglas de negocio (KPIs) a partir de datos brutos.\n",
    "\n",
    "### Buenas prácticas profesionales y errores comunes\n",
    "- **Buenas prácticas:** nombrar columnas agregadas con alias claros; validar cardinalidades; evitar `apply` cuando una operación vectorizada es suficiente.\n",
    "- **Errores comunes:** no resetear el índice tras agregaciones; usar `apply` de forma innecesaria (penaliza rendimiento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73f43c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas por categoría:\n",
      "      categoria  total_unidades  precio_promedio  productos_distintos\n",
      "0        Audio               4            77.75                    2\n",
      "1     Displays               3           204.50                    1\n",
      "2  Periféricos              11            23.30                    2\n",
      "---------------------------------------- \n",
      "\n",
      "Rango de precios por categoría:\n",
      "      categoria  rango_precio\n",
      "0        Audio          84.5\n",
      "1     Displays          11.0\n",
      "2  Periféricos          14.9\n",
      "     categoria  unidades  z_unidades_por_categoria\n",
      "0        Audio         3                  1.000000\n",
      "1  Periféricos         2                 -1.336306\n",
      "2     Displays         1                 -1.000000\n",
      "3  Periféricos         5                  1.069045\n",
      "4        Audio         1                 -1.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Ejemplo en Python: groupby, agg y apply\n",
    "\n",
    "df = pd.read_csv(\"./data/productos.csv\", parse_dates=['fecha'])\n",
    "\n",
    "# Métricas por categoría\n",
    "agg_por_categoria = (\n",
    "  df.groupby('categoria')\n",
    "    .agg(\n",
    "      total_unidades=('unidades', 'sum'),\n",
    "      precio_promedio=('precio', 'mean'),\n",
    "      productos_distintos=('producto', 'nunique')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "print(\"Métricas por categoría:\\n\", agg_por_categoria )\n",
    "print(\"-\" * 40, \"\\n\")\n",
    "\n",
    "# Función Personalizadas: rango( max - min ) por categoría\n",
    "def rango(serie):\n",
    "  return serie.max() - serie.min()\n",
    "\n",
    "rango_precios = df.groupby('categoria')['precio'].apply(rango).reset_index(name='rango_precio')\n",
    "print(\"Rango de precios por categoría:\\n\", rango_precios)\n",
    "\n",
    "# Transformaciones por grupo: Normalizar unidades\n",
    "def zscore(serie):\n",
    "  return (serie - serie.mean()) / serie.std(ddof=0)\n",
    "\n",
    "df[\"z_unidades_por_categoria\"] = df.groupby('categoria')['unidades'].transform(zscore)\n",
    "print(df[[\"categoria\", \"unidades\", \"z_unidades_por_categoria\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e49a95",
   "metadata": {},
   "source": [
    "# Ejercicios Integradores\n",
    "\n",
    "A continuación se proponen ejercicios que integran carga, selección/filtrado y agregación/transformación. Se presentan **pistas** y, posteriormente, una **solución propuesta**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977911b2",
   "metadata": {},
   "source": [
    "## Ejercicio 1. Reporte de ventas por categoría y ticket promedio\n",
    "**Contexto técnico:** Eres analista de Business Intelligence en una tienda en línea. Debes generar un **reporte semanal** para dirección con métricas por categoría que orienten decisiones de pricing y stock.\n",
    "\n",
    "**Datos / entradas:** Utiliza un `DataFrame` con columnas `categoria`, `precio`, `unidades` y `fecha`. Puedes partir de un CSV simulado en memoria (similar a los ejemplos).\n",
    "\n",
    "**Requerimientos:**\n",
    "1. Calcular **ventas totales** por categoría (`precio * unidades`).\n",
    "2. Calcular el **ticket promedio** por categoría (promedio de `precio` ponderado por `unidades` o simple, justifica tu elección).\n",
    "3. Ordenar el resultado por ventas totales descendente.\n",
    "\n",
    "**Criterios de aceptación:**\n",
    "- El resultado debe ser un `DataFrame` con columnas: `categoria`, `ventas_totales`, `ticket_promedio`.\n",
    "- Debe estar ordenado por `ventas_totales` de mayor a menor.\n",
    "- Debes mostrar las 5 primeras filas con `.head()`.\n",
    "\n",
    "**Pistas:**\n",
    "- Crea una columna auxiliar `venta = precio * unidades`.\n",
    "- Usa `groupby('categoria').agg(...)` con alias de columnas.\n",
    "- Para ticket promedio ponderado, usa una razón de sumatorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83247941",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Solución Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e457b8ec",
   "metadata": {},
   "source": [
    "## Ejercicio 2. Segmentación temporal y filtrado avanzado\n",
    "**Contexto técnico:** Como analista de datos, debes preparar un **subset** de registros para un experimento A/B que solo considera transacciones realizadas **a partir** de una fecha y con **precio** dentro de un rango específico.\n",
    "\n",
    "**Datos / entradas:** Un `DataFrame` con `fecha` (tipo fecha), `precio` y `categoria`.\n",
    "\n",
    "**Requerimientos:**\n",
    "1. Filtrar registros con `fecha >= 2024-01-04`.\n",
    "2. Mantener solo filas con `precio` en el rango `[20, 200]`.\n",
    "3. Seleccionar únicamente las columnas `fecha`, `categoria` y `precio`.\n",
    "4. Mostrar las primeras 3 filas resultantes.\n",
    "\n",
    "**Criterios de aceptación:**\n",
    "- El `DataFrame` filtrado solo contiene precios dentro del rango y fechas a partir del umbral.\n",
    "- Columnas en el orden solicitado.\n",
    "\n",
    "**Pistas:**\n",
    "- Recuerda usar paréntesis al combinar condiciones con `&`.\n",
    "- Usa `loc` para seleccionar columnas por etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14d84d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Solución Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d9c450",
   "metadata": {},
   "source": [
    "## Ejercicio 3. Enriquecimiento con transformaciones por grupo\n",
    "**Contexto técnico:** Como científico/a de datos, necesitas **normalizar** la columna `unidades` dentro de cada `categoria` para comparar el desempeño relativo entre productos, independientemente de su escala.\n",
    "\n",
    "**Datos / entradas:** `DataFrame` con `categoria` y `unidades` (enteros positivos).\n",
    "\n",
    "**Requerimientos:**\n",
    "1. Calcular el **z-score** por categoría sobre `unidades` y añadirlo como columna `z_unidades`.\n",
    "2. Comprobar que la media por categoría de `z_unidades` está cercana a 0.\n",
    "3. Mostrar una tabla con `categoria`, `unidades`, `z_unidades` (primeras 5 filas).\n",
    "\n",
    "**Criterios de aceptación:**\n",
    "- Nueva columna `z_unidades` creada correctamente.\n",
    "- Media por categoría de `z_unidades` ≈ 0 (diferencias menores por redondeo).\n",
    "\n",
    "**Pistas:**\n",
    "- Usa `groupby('categoria')['unidades'].transform(...)` con una función que aplique z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c38c75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Solución Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dc9cbd",
   "metadata": {},
   "source": [
    "## Ejercicio 4 (opcional). Exportación del resultado y validaciones mínimas\n",
    "**Contexto técnico:** Debes entregar a un equipo externo un **extracto** con métricas por categoría. El equipo requiere un archivo **Excel** con nombre y ubicación definidos.\n",
    "\n",
    "**Datos / entradas:** Resultado del **Ejercicio 1** u otro `DataFrame` agregado.\n",
    "\n",
    "**Requerimientos:**\n",
    "1. Validar que no existan valores nulos en las columnas clave.\n",
    "2. Exportar a Excel sin índice.\n",
    "3. Confirmar ruta de salida y tamaño del archivo.\n",
    "\n",
    "**Criterios de aceptación:**\n",
    "- Archivo `.xlsx` generado en la ruta configurada, sin índice.\n",
    "- Columnas clave sin nulos.\n",
    "\n",
    "**Pistas:**\n",
    "- Usa `notna().all()` para columnas clave.\n",
    "- Usa `to_excel(ruta, index=False)` y revisa con el sistema de archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfebfc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Solución Ejercicio 4"
   ]
  }
 ],
 "metadata": {
  "authors": [
   "Equipo docente - Fundamentos de Programación y Analítica de Datos con Python"
  ],
  "created": "2025-09-16T18:00:38.086380+00:00",
  "description": "Sección: Manipulación y Transformación de Datos con Pandas. Uso de Pandas para carga, selección/filtrado y operaciones de agregación/transformación sobre datos tabulares.",
  "kernelspec": {
   "display_name": "Python (python-course)",
   "language": "python",
   "name": "python-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
